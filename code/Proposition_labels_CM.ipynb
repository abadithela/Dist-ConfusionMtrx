{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa2bc0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 63.690 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 38.8 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "# Proposition based distance parametrized confusion matrices\n",
    "# Apurva Badithela\n",
    "# 6/7/22\n",
    "\n",
    "import os\n",
    "import pdb\n",
    "from utils import *\n",
    "dataroot=\"/Users/apurvabadithela/Documents/software/nuscenes/data/sets/nuscenes\"\n",
    "dataroot_ext=\"/Volumes/Extreme SSD/nuscenes\"\n",
    "from nuscenes.nuscenes import NuScenes, NuScenesExplorer\n",
    "from yolo_bboxes import *\n",
    "from shapely.geometry import MultiPoint, box\n",
    "import pickle as pkl\n",
    "from parse_matchings import ConfusionMatrix, cluster_categories\n",
    "import numpy as np\n",
    "from itertools import chain, combinations\n",
    "nusc = NuScenes(version='v1.0-trainval', dataroot=dataroot_ext)\n",
    "namesfile = 'data/coco.names'\n",
    "save_data_ext=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ce72655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: {'empty'}, 0: {'pedestrian'}, 1: {'obstacle'}, 2: {'pedestrian', 'obstacle'}}\n",
      "{('empty',): 3, ('pedestrian',): 0, ('obstacle',): 1, ('pedestrian', 'obstacle'): 2}\n"
     ]
    }
   ],
   "source": [
    "### Load the COCO object classes\n",
    "class_names = load_class_names(namesfile)\n",
    "cm_type = \"prop_based\"\n",
    "nms_thresh = 0.6\n",
    "iou_thresh = 0.4\n",
    "horizon = 120\n",
    "discrete_horizon = 5\n",
    "sensor = 'CAM_FRONT' # Sensor rleevant in this study\n",
    "PLOT = True\n",
    "\n",
    "# Get number of classes in the confusion matrix:\n",
    "# Nclasses: num of different objects\n",
    "# Nprops: num of different confusion matrices\n",
    "class_dict = {0: 'pedestrian', 1:'obstacle', 2:'empty'}\n",
    "n = len(list(class_dict.keys()))\n",
    "def get_nclasses(Nclasses):\n",
    "    if cm_type == \"prop_based\":\n",
    "        return 2**(Nclasses-1)\n",
    "    else:\n",
    "        return Nclasses\n",
    "\n",
    "Nclasses = get_nclasses(n)\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(1, len(s)+1))\n",
    "\n",
    "cm_class_dict = dict()\n",
    "cm_class_dict[Nclasses-1] = {'empty'} # Building an order\n",
    "key = 0\n",
    "empty_key = [k for k,v in class_dict.items() if v == 'empty'][0] # There should only be one empty key\n",
    "class_keys = list(class_dict.keys())[:-1] # Fix; make better\n",
    "cm_classes_keys = list(powerset(class_keys))\n",
    "\n",
    "for k in range(len(cm_classes_keys)):\n",
    "    class_combinations = cm_classes_keys[k]\n",
    "    cm_class_dict[k] = {class_dict[class_combinations[0]]}\n",
    "    for l in range(1, len(class_combinations)):\n",
    "        cm_class_dict[k] |= {class_dict[class_combinations[l]]}\n",
    "    \n",
    "print(cm_class_dict)\n",
    "rev_class_dict = {v: k for k, v in class_dict.items()}\n",
    "rev_cm_class_dict = {tuple(v): k for k, v in cm_class_dict.items()}\n",
    "\n",
    "print(rev_cm_class_dict)\n",
    "\n",
    "\n",
    "# Cluster categories from nuscenes dataset:\n",
    "categories = []\n",
    "for category_dict in nusc.category:\n",
    "    cat_name = category_dict['name']\n",
    "    if cat_name not in categories:\n",
    "        categories.append(cat_name)\n",
    "sup_categories = cluster_categories(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac92a554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all instances captured in the first annotation of the object:\n",
    "def get_yolo_object_type(box, class_names):\n",
    "    # print('Objects Found and Confidence Level:\\n')\n",
    "    if len(box) >= 7 and class_names:\n",
    "        cls_conf = box[5]\n",
    "        cls_id = box[6]\n",
    "        return class_names[cls_id], cls_conf\n",
    "\n",
    "# Function to get yOlO Boxes:\n",
    "def get_yolo_boxes(yolo, data_path):\n",
    "    boxes, boxes_pixels_yolo = yolo.yolo(data_path)\n",
    "    return boxes, boxes_pixels_yolo\n",
    "\n",
    "# function to get nuscenes boxes:\n",
    "def get_gt_boxes(sample):\n",
    "    # Get front camera data:\n",
    "    cam_front_data_f = nusc.get('sample_data', sample['data'][sensor])\n",
    "    data_path_f, boxes, camera_intrinsic = nusc.get_sample_data(cam_front_data_f['token'], box_vis_level=BoxVisibility.ANY)\n",
    "    print(\"Accessed data for ground truth boxes\")\n",
    "    # pdb.set_trace()\n",
    "    boxes_gt_pixels = box_nusc(boxes, camera_intrinsic)\n",
    "    boxes_gt = []\n",
    "    return boxes_gt_pixels, boxes, data_path_f, cam_front_data_f, camera_intrinsic\n",
    "\n",
    "def prepare_gt_box(nubox):\n",
    "    xmin = nubox[0]\n",
    "    ymin = nubox[1]\n",
    "    xmax = nubox[2]\n",
    "    ymax = nubox[3]\n",
    "    new_nusc_box = [xmin, ymin, xmax-xmin, ymin-ymax]\n",
    "    return new_nusc_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "794a39ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare boxes:\n",
    "# To-DO: Cleanup code\n",
    "def compare_boxes(boxes_gt, boxes_yolo_pixels):\n",
    "    matchings = {}\n",
    "    matched_nusc_boxes = []\n",
    "    matched_yolo_boxes = []\n",
    "    boxes_gt_dict = {}\n",
    "    boxes_yolo_dict = {}\n",
    "    i = 0\n",
    "    for box_gt in boxes_gt:\n",
    "        boxes_gt_dict[i] = prepare_gt_box(box_gt)\n",
    "        matchings[i] = dict()\n",
    "        matchings[i][\"yolo_match\"] = dict()\n",
    "        i += 1\n",
    "    i= 0\n",
    "    for box_yolo in boxes_yolo_pixels:\n",
    "        boxes_yolo_dict[i] = prepare_yolo_box(box_yolo)\n",
    "        i += 1\n",
    "\n",
    "    for box_gt_i in boxes_gt_dict.keys():\n",
    "        for box_yolo_i in boxes_yolo_dict.keys():\n",
    "            box_gt = boxes_gt_dict[box_gt_i]\n",
    "            box_yolo = boxes_yolo_dict[box_yolo_i]\n",
    "            iou = compute_iou(box_gt, box_yolo)\n",
    "\n",
    "            if iou >= 0.7:\n",
    "                matchings[box_gt_i][\"yolo_match\"][\"box_id\"] = box_yolo_i\n",
    "                matched_nusc_boxes.append(boxes_gt_dict[box_gt_i])\n",
    "                matched_yolo_boxes.append(boxes_yolo_dict[box_yolo_i])\n",
    "                print(\"Match found\")\n",
    "    return matchings, matched_nusc_boxes, matched_yolo_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f3e240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process list of observations seen at a distance j:\n",
    "# ann_at_j is a list of predictions for the ground truth annotation, gt_ann, at the same distance in a single image\n",
    "\n",
    "def process_anns_at_j(predictions, gt_val, scene_cmi):\n",
    "    predicted_prop = set(predictions)\n",
    "    true_prop = set(gt_val)\n",
    "    assert true_prop != {'empty'}\n",
    "\n",
    "    if 'empty' in true_prop:\n",
    "        true_prop.remove('empty')\n",
    "    if 'empty' in predicted_prop and predicted_prop != {'empty'}:\n",
    "        predicted_prop.remove('empty')\n",
    "    \n",
    "    for k, v in rev_cm_class_dict.items():\n",
    "        if predicted_prop == set(k):\n",
    "            pred_idx = k\n",
    "        if true_prop == set(k):\n",
    "            true_idx = k\n",
    "            \n",
    "    row = rev_cm_class_dict[pred_idx]\n",
    "    col = rev_cm_class_dict[true_idx]\n",
    "    scene_cmi[row, col] += 1.0\n",
    "    return scene_cmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e6cb463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to construct the confusion matrix from the categorized annotations :\n",
    "def construct_confusion_matrix(scene_obj):\n",
    "    discretization = np.linspace(discrete_horizon, horizon, int(horizon/discrete_horizon))\n",
    "    scene_cm = {i: np.zeros((Nclasses, Nclasses)) for i in range(len(discretization))} # distionary of confusion\n",
    "    \n",
    "    # class_dict = {0: 'pedestrian', 1:'vehicle', 2:'obstacle', 3:'empty'}\n",
    "    obj_det=False\n",
    "    \n",
    "    # Discretization of the state space\n",
    "    for i in range(len(discretization)): \n",
    "        objs_at_dist_i = scene_obj[i]\n",
    "        if objs_at_dist_i == []: # If no object at that distance return empty\n",
    "            true_class = tuple('empty')\n",
    "            pred_class = tuple('empty')\n",
    "            row = rev_cm_class_dict[pred_class]\n",
    "            col = rev_cm_class_dict[true_class]\n",
    "            scene_cm[i][row, col] += 1\n",
    "        else:\n",
    "            obj_det = True\n",
    "            predictions =  [obj[1] for obj in objs_at_dist_i]\n",
    "            gt_val =  [obj[0] for obj in objs_at_dist_i]\n",
    "            scene_cm[i] = process_anns_at_j(predictions, gt_val, scene_cm[i])\n",
    "    return scene_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4b54384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scene confusion matrix:\n",
    "# scene_cm is an N-by-N matrix where scene_cm(i,j) has the ith location of the\n",
    "def scene_confusion_matrix(distance_to_annotations, matchings, boxes_nusc):\n",
    "    discretization = np.linspace(discrete_horizon, horizon, int(horizon/discrete_horizon))\n",
    "    scene_obj = {i: [] for i in range(len(discretization))} # distionary of confusion matrix by distance\n",
    "    # Categorize ground truth annotations based on their distance from ego:\n",
    "    for j in range(len(boxes_nusc)):\n",
    "        nubox = boxes_nusc[j] # Box object\n",
    "        distance_to_ego = distance_to_annotations[nubox.token]\n",
    "        if any(distance_to_ego < discretization):\n",
    "            dindx = np.where(distance_to_ego < discretization)[0][0] # First index\n",
    "            true_class = sup_categories[matchings[j]['category']]\n",
    "            if matchings[j][\"yolo_match\"]:\n",
    "                pred_class = matchings[j]['yolo_match']['pred_class'] # Find the classified matching, otherwise empty\n",
    "            else:\n",
    "                pred_class = 'empty'\n",
    "            scene_obj[dindx].append((true_class, pred_class)) # Scenario of all objects at a given distance from the ego \n",
    "    scene_cm = construct_confusion_matrix(scene_obj)\n",
    "    return scene_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49b60a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute distance to ego\n",
    "def compute_distance_to_ego(boxes_nusc, cam_data):\n",
    "    sample_token = cam_data['token']\n",
    "    sd_record = nusc.get('sample_data', sample_token)\n",
    "    cs_record = nusc.get('calibrated_sensor', sd_record['calibrated_sensor_token'])\n",
    "    curr_sample_record = nusc.get('sample', sd_record['sample_token'])\n",
    "    curr_ann_recs = [nusc.get('sample_annotation', token) for token in curr_sample_record['anns']]\n",
    "    cam_front_boxes_nusc = list([box.token for box in boxes_nusc])\n",
    "    cam_front_anns = [ann_rec for ann_rec in curr_ann_recs if curr_ann_recs in cam_front_boxes_nusc] # only look at front camera annotations:\n",
    "    # Sanity check:\n",
    "    assert cam_front_anns!=None\n",
    "\n",
    "    # Move box to ego vehicle coordinate system from sensor coordinate system:\n",
    "    distance_to_ego = dict()\n",
    "    boxes_copy = boxes_nusc.copy()\n",
    "    for box in boxes_copy:\n",
    "        box.rotate(Quaternion(cs_record['rotation']))\n",
    "        box.translate(np.array(cs_record['translation']))\n",
    "        box_pos = box.center\n",
    "        distance_to_ego[box.token] = np.linalg.norm(box_pos)\n",
    "    return distance_to_ego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48895566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'empty'}, {'pedestrian'}, {'obstacle'}, {'obstacle', 'pedestrian'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cm_class_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d977b6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pedestrian',), ('obstacle',), ('pedestrian', 'obstacle')]\n",
      "\n",
      "850ding weights. Please Wait...100.00% Complete\n",
      "Iteration ........  1\n",
      "Getting Nuscenes ground truth 2D boxes: \n",
      "Accessed data for ground truth boxes\n",
      "Getting YoLo predicted 2D boxes: \n",
      "\n",
      "\n",
      "It took 1.379 seconds to detect the objects in the image.\n",
      "\n",
      "Number of Objects Detected: 3 \n",
      "\n",
      "1600\n",
      "900\n",
      "Modified pixels: \n",
      "416\n",
      "416\n",
      "Objects Found and Confidence Level:\n",
      "\n",
      "1. truck: 0.997722\n",
      "2. traffic light: 1.000000\n",
      "3. traffic light: 0.999999\n",
      "Match found\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "('e', 'm', 'p', 't', 'y')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hz/k2w5mcvs7_xfg7cxqbdjfdzr0000gn/T/ipykernel_1776/3682023597.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m# Construct confusion matrix for this scene:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mscene_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscene_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance_to_annotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatchings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes_nusc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_conf_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene_cm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;31m# Store all matchings at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/hz/k2w5mcvs7_xfg7cxqbdjfdzr0000gn/T/ipykernel_1776/2574343209.py\u001b[0m in \u001b[0;36mscene_confusion_matrix\u001b[0;34m(distance_to_annotations, matchings, boxes_nusc)\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mpred_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'empty'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mscene_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdindx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Scenario of all objects at a given distance from the ego\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mscene_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscene_cm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/hz/k2w5mcvs7_xfg7cxqbdjfdzr0000gn/T/ipykernel_1776/3367660714.py\u001b[0m in \u001b[0;36mconstruct_confusion_matrix\u001b[0;34m(scene_obj)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mtrue_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'empty'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mpred_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'empty'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrev_cm_class_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrev_cm_class_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mscene_cm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('e', 'm', 'p', 't', 'y')"
     ]
    }
   ],
   "source": [
    "# Iterating over scenes\n",
    "# print(nusc.list_sample)\n",
    "if __name__ == '__main__':\n",
    "    classes = [tuple(c) for c in list(cm_class_dict.values()) if c!={'empty'}]\n",
    "    print(classes)\n",
    "    horizon = 100\n",
    "    discrete_horizon = 10\n",
    "    distance_bins = int(horizon/discrete_horizon)\n",
    "    C = ConfusionMatrix(classes, horizon, distance_bins=distance_bins)\n",
    "    Nscenes = len(nusc.scene)\n",
    "\n",
    "    # instantiating YoLo obkect:\n",
    "    yolo = YoLo( nms_thresh, iou_thresh)\n",
    "    print(Nscenes)\n",
    "    for n in range(1,Nscenes+1):\n",
    "        print(\"Iteration ........ \", str(n))\n",
    "        objects_detected = dict() # Matchings over objects detected\n",
    "        scene = nusc.scene[n-1]\n",
    "        # iterating over timestamps / samples:\n",
    "        sample_token = scene['first_sample_token']\n",
    "        sample = nusc.get('sample', scene['first_sample_token'])\n",
    "        sample_number = 1\n",
    "\n",
    "        while sample_number < scene['nbr_samples']:\n",
    "            # Get ground truth 2D boxes for front camera:\n",
    "            print(\"Getting Nuscenes ground truth 2D boxes: \")\n",
    "            boxes_gt_pixels, boxes_nusc, data_path, cam_data, camera_intrinsic = get_gt_boxes(sample)\n",
    "            # Get Yolo Boxes:\n",
    "            print(\"Getting YoLo predicted 2D boxes: \")\n",
    "            boxes_yolo, boxes_yolo_pixels = get_yolo_boxes(yolo, data_path)\n",
    "\n",
    "            # Compare bounding boxes:\n",
    "            matchings, matched_gt_boxes, matched_yolo_boxes = compare_boxes(boxes_gt_pixels, boxes_yolo_pixels)\n",
    "            # compute distance from ego to annotations:\n",
    "\n",
    "            distance_to_annotations = compute_distance_to_ego(boxes_nusc, cam_data)\n",
    "\n",
    "            # Add annotations:\n",
    "            for j in range(len(boxes_nusc)):\n",
    "                nubox = boxes_nusc[j] # Box object\n",
    "                matchings[j]['nusc_token'] = nubox.token\n",
    "                matchings[j]['distance_to_ego'] = distance_to_annotations[nubox.token] # Distance to ego\n",
    "                matchings[j]['category'] = nubox.name\n",
    "\n",
    "                if matchings[j][\"yolo_match\"]:\n",
    "                    yolo_id = matchings[j][\"yolo_match\"][\"box_id\"]\n",
    "                    yolo_box_id = boxes_yolo[yolo_id]\n",
    "                    if class_names[yolo_box_id[6]] in [\"car\", \"truck\", \"bus\"]:\n",
    "                        matchings[j][\"yolo_match\"][\"pred_class\"] = \"obstacle\"\n",
    "                    elif class_names[yolo_box_id[6]] == \"person\":\n",
    "                        matchings[j][\"yolo_match\"][\"pred_class\"] = \"pedestrian\"\n",
    "                    else:\n",
    "                        matchings[j][\"yolo_match\"][\"pred_class\"] = \"obstacle\"\n",
    "\n",
    "            # Construct confusion matrix for this scene:\n",
    "            scene_cm = scene_confusion_matrix(distance_to_annotations, matchings, boxes_nusc)\n",
    "            C.add_conf_matrix(scene_cm)\n",
    "            # Store all matchings at the end\n",
    "            objects_detected[sample_number] = matchings\n",
    "            # Update sample number:\n",
    "            sample_token = sample['next']\n",
    "            sample = nusc.get('sample', sample_token)\n",
    "            sample_number += 1\n",
    "\n",
    "        # Save data:\n",
    "        if save_data_ext:\n",
    "            dirname = \"Volumes/Extreme SSD/cm_processing/matchings\"\n",
    "            \n",
    "        else:\n",
    "            cwd = os.getcwd()\n",
    "            dirname = cwd + \"/matchings_new\"\n",
    "            # pdb.set_trace()\n",
    "        if os.path.exists(dirname) is False:\n",
    "            os.mkdir(dirname)\n",
    "        fname = dirname + \"/scene_\"+str(n)+\"_matchings.p\"\n",
    "        pkl.dump(objects_detected, open(fname, \"wb\"))\n",
    "\n",
    "    # Print confusion matrix:\n",
    "    C.print()\n",
    "    dirname = cwd + \"/\"\n",
    "    fname = dirname + \"cm/trainval1_prop_label_hrzn_\" + str(horizon) + \"_distbin_\" + str(distance_bins) + \".p\"\n",
    "    pkl.dump(C.C, open(fname, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7fcf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def print_cm(C):\n",
    "    # TO-DO: make it generic\n",
    "    for i in range(C.distance_bins):\n",
    "        print(\" \")\n",
    "        headers=['pred \\ true']\n",
    "        predictions = []\n",
    "        for k,v in C.map.items():\n",
    "            headers.append(v)\n",
    "            pred_class = v\n",
    "            pred_row = list(C.C[i][k,:])\n",
    "            predictions.append([pred_class, *pred_row])\n",
    "\n",
    "        print(\"Printing confusion matrix from distance d <= {0}\".format(C.markers[i]))\n",
    "\n",
    "        table_C = tabulate(predictions, headers=headers)\n",
    "        print(table_C)\n",
    "\n",
    "print_cm(C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a0bd3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token': '73030fb67d3c46cfb5e590168088ae39',\n",
       " 'log_token': '6b6513e6c8384cec88775cae30b78c0e',\n",
       " 'nbr_samples': 40,\n",
       " 'first_sample_token': 'e93e98b63d3b40209056d129dc53ceee',\n",
       " 'last_sample_token': '40e413c922184255a94f08d3c10037e0',\n",
       " 'name': 'scene-0001',\n",
       " 'description': 'Construction, maneuver between several trucks'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene=nusc.scene[0]\n",
    "scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743c9a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
